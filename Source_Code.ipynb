{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61309af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T15:00:30.163098Z",
     "iopub.status.busy": "2024-04-05T15:00:30.162626Z",
     "iopub.status.idle": "2024-04-05T15:00:35.212465Z",
     "shell.execute_reply": "2024-04-05T15:00:35.210833Z",
     "shell.execute_reply.started": "2024-04-05T15:00:30.163067Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Load the datasets\n",
    "X = pd.read_csv(r\"C:\\Users\\sanjay p\\OneDrive\\Desktop\\bitcode breakers\\train.csv\")\n",
    "final = pd.read_csv(r\"C:\\Users\\sanjay p\\OneDrive\\Desktop\\bitcode breakers\\test.csv\")\n",
    "\n",
    "y = X[['LABEL']]\n",
    "# Replace label values for binary classification\n",
    "y['LABEL'] = y['LABEL'].replace({1:0, 2:1})\n",
    "\n",
    "ID = final[['ID']]\n",
    "# Drop unnecessary columns from test data\n",
    "final = final.drop(columns=['Unnamed: 0','ID'],axis=1)\n",
    "\n",
    "# Drop unnecessary columns from training data\n",
    "X = X.drop(columns=['Unnamed: 0','LABEL'],axis=1)\n",
    "\n",
    "# Define transformation pipeline for preprocessing\n",
    "tran = Pipeline(steps=[ # Impute missing values with mean\n",
    "            ('pca', PCA(n_components=9)), # Perform PCA with 9 components\n",
    "            ('scaler', StandardScaler())  # Standardize features\n",
    "        ])\n",
    "\n",
    "features = X.columns\n",
    "# Define preprocessor to handle preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "         ('t',tran, features) # Apply transformation pipeline to features\n",
    "    ])\n",
    "\n",
    "# Define stratified k-fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8612daef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T15:00:41.959804Z",
     "iopub.status.busy": "2024-04-05T15:00:41.959096Z",
     "iopub.status.idle": "2024-04-05T15:00:41.969458Z",
     "shell.execute_reply": "2024-04-05T15:00:41.968289Z",
     "shell.execute_reply.started": "2024-04-05T15:00:41.959757Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a hyperparameter search space for BaggingCLassifier and XGBClassifier\n",
    "space = {\n",
    "    'max_samples': hp.uniform('max_samples', 0.7, 1.0),\n",
    "    'max_features': hp.uniform('max_features', 0.7, 1.0),\n",
    "    'estimator': {\n",
    "        'max_depth': hp.choice('max_depth', range(2, 10)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.0003, 0.007),\n",
    "        'min_child_weight': hp.uniform('min_child_weight', 1, 12),\n",
    "        'gamma': hp.loguniform('gamma', low=np.log(0.001), high=np.log(5)),  # Gamma from 0 to 5 (log-uniform)\n",
    "        'reg_alpha': hp.loguniform('reg_alpha', low=np.log(0.0001), high=np.log(0.8)),  # Alpha from 0 to 0.8 (log-uniform)\n",
    "        'reg_lambda': hp.loguniform('reg_lambda', low=np.log(1), high=np.log(5)),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'colsample_bynode': hp.uniform('colsample_bynode', 0.6, 1.0),\n",
    "        'colsample_bylevel': hp.uniform('colsample_bylevel', 0.6, 1.0)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40cd477a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T15:58:56.394549Z",
     "iopub.status.busy": "2024-04-05T15:58:56.394034Z",
     "iopub.status.idle": "2024-04-05T17:16:07.979961Z",
     "shell.execute_reply": "2024-04-05T17:16:07.978718Z",
     "shell.execute_reply.started": "2024-04-05T15:58:56.394512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [1:17:11<00:00, 115.79s/trial, best loss: -0.992726788022092]\n",
      "Best hyperparameters: {'colsample_bylevel': 0.7550550688041309, 'colsample_bynode': 0.8422597946469974, 'colsample_bytree': 0.8035651858278754, 'gamma': 0.01906530906714543, 'learning_rate': 0.006046234261242088, 'max_depth': 7, 'max_features': 0.9853464615314544, 'max_samples': 0.9864341340067273, 'min_child_weight': 3.951572290815913, 'reg_alpha': 0.00014489149306128374, 'reg_lambda': 1.0574422551197646}\n"
     ]
    }
   ],
   "source": [
    "def objective(space):\n",
    "    max_samples = space['max_samples']\n",
    "    max_features = space['max_features']\n",
    "    xgb_params = {\n",
    "        'max_depth': space['estimator']['max_depth'],\n",
    "        'learning_rate': space['estimator']['learning_rate'],\n",
    "        'gamma': space['estimator']['gamma'],\n",
    "        'min_child_weight': space['estimator']['min_child_weight'],\n",
    "        'reg_alpha': space['estimator']['reg_alpha'],\n",
    "        'reg_lambda': space['estimator']['reg_lambda'],\n",
    "        'colsample_bytree': space['estimator']['colsample_bytree'],\n",
    "        'colsample_bynode': space['estimator']['colsample_bynode'],\n",
    "        'colsample_bylevel': space['estimator']['colsample_bylevel']\n",
    "    }\n",
    "    mean_accuracy_score = []\n",
    "    # Flatten the target variable y\n",
    "    y_data  = y.values.ravel()\n",
    "    # Calculate scale_pos_weight for XGBClassifier\n",
    "    scale_pos_weight = (len(y_data) - y_data.sum()) / y_data.sum()\n",
    "    # Define the BaggingClassifier with XGBClassifier as the base estimator\n",
    "    xgb_classifier = XGBClassifier(n_estimators = 300, scale_pos_weight=scale_pos_weight, objective=\"binary:logistic\",\n",
    "                                    random_state=42, **xgb_params)\n",
    "    model_bagging = BaggingClassifier(\n",
    "        estimator=xgb_classifier,\n",
    "        n_estimators = 70,\n",
    "        max_samples=max_samples,\n",
    "        max_features=max_features,\n",
    "        bootstrap=True,\n",
    "        random_state=42  # Set random state for reproducibility\n",
    "    )\n",
    "    # Perform stratified k-fold cross-validation\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train_skf = preprocessor.fit_transform(X.iloc[train_index])\n",
    "        X_test_skf = preprocessor.transform(X.iloc[test_index])\n",
    "        y_train_skf, y_test_skf = y.iloc[train_index], y.iloc[test_index]\n",
    "        y_train_skf = y_train_skf.values.ravel()\n",
    "        y_test_skf = y_test_skf.values.ravel()\n",
    "\n",
    "        # Fit the model\n",
    "        model_bagging.fit(X_train_skf, y_train_skf)\n",
    "        y_pred_skf = model_bagging.predict(X_test_skf)\n",
    "        accuracy = accuracy_score(y_test_skf, y_pred_skf)\n",
    "        mean_accuracy_score.append(accuracy)\n",
    "    # Calculate mean accuracy   \n",
    "    mean_accuracy = np.mean(mean_accuracy_score)\n",
    "    # Return loss (negative mean accuracy) and optimization status\n",
    "    return {'loss': -mean_accuracy, 'status': STATUS_OK}\n",
    "\n",
    "# Run hyperparameter optimization using Hyperopt\n",
    "trials = Trials()\n",
    "best_params = fmin(objective, space, rstate=np.random.default_rng(42), algo=tpe.suggest,\n",
    "                   max_evals=40, trials=trials)\n",
    "# Print best hyperparameters found\n",
    "print(\"Best hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa652779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T17:22:36.558267Z",
     "iopub.status.busy": "2024-04-05T17:22:36.557828Z",
     "iopub.status.idle": "2024-04-05T17:22:36.565383Z",
     "shell.execute_reply": "2024-04-05T17:22:36.564033Z",
     "shell.execute_reply.started": "2024-04-05T17:22:36.558226Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the best hyperparameters obtained from hyperparameter tuning\n",
    "best_params = {'colsample_bylevel': 0.7550550688041309, 'colsample_bynode': 0.8422597946469974, 'colsample_bytree': 0.8035651858278754, 'gamma': 0.01906530906714543, 'learning_rate': 0.006046234261242088, 'max_depth': 9, \n",
    "                'min_child_weight': 3.951572290815913, 'reg_alpha': 0.00014489149306128374, 'reg_lambda': 1.0574422551197646}\n",
    "bp = {'max_features': 0.9853464615314544, 'max_samples': 0.9864341340067273}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b941c81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T17:23:29.598730Z",
     "iopub.status.busy": "2024-04-05T17:23:29.598251Z",
     "iopub.status.idle": "2024-04-05T17:26:12.811576Z",
     "shell.execute_reply": "2024-04-05T17:26:12.810360Z",
     "shell.execute_reply.started": "2024-04-05T17:23:29.598692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call evaluate function\n",
      "mean_accuracy: 0.992726788022092\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate():\n",
    "# Flatten the target variable y\n",
    "    y_data  = y.values.ravel()\n",
    "    mean_accuracy_score = []\n",
    "    # Calculate scale_pos_weight for XGBClassifier\n",
    "    scale_pos_weight = (len(y_data) - y_data.sum()) / y_data.sum()\n",
    "    # Initialize BaggingClassifier & XGBClassifier with best hyperparameters\n",
    "    model_bagging = BaggingClassifier(\n",
    "            estimator=XGBClassifier(n_estimators=300, scale_pos_weight=scale_pos_weight, objective=\"binary:logistic\", \n",
    "                                    random_state=42, **best_params),n_estimators=70,\n",
    "            random_state=42,\n",
    "            bootstrap=True, **bp\n",
    "        )\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train_skf = preprocessor.fit_transform(X.iloc[train_index])\n",
    "        X_test_skf = preprocessor.transform(X.iloc[test_index])\n",
    "        y_train_skf, y_test_skf = y.iloc[train_index], y.iloc[test_index]\n",
    "        y_train_skf = y_train_skf.values.ravel()\n",
    "        y_test_skf = y_test_skf.values.ravel()\n",
    "        \n",
    "        # Fit the model\n",
    "        model_bagging.fit(X_train_skf, y_train_skf)\n",
    "        y_pred_skf = model_bagging.predict(X_test_skf)\n",
    "        accuracy = accuracy_score(y_test_skf, y_pred_skf)\n",
    "        mean_accuracy_score.append(accuracy)\n",
    "    # Calculate mean accuracy score    \n",
    "    mean_accuracy = np.mean(mean_accuracy_score)\n",
    "    # Print mean accuracy score  \n",
    "    print(\"mean_accuracy:\", mean_accuracy)\n",
    "# Call the evaluate function\n",
    "print(\"call evaluate function\")\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a560f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T17:27:26.813526Z",
     "iopub.status.busy": "2024-04-05T17:27:26.813076Z",
     "iopub.status.idle": "2024-04-05T17:28:04.702255Z",
     "shell.execute_reply": "2024-04-05T17:28:04.700638Z",
     "shell.execute_reply.started": "2024-04-05T17:27:26.813489Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ID_array = ID['ID'].to_numpy()\n",
    "# Transform features in the test set using the preprocessor fitted on the training data\n",
    "X_pre = preprocessor.fit_transform(X)\n",
    "final_pre = preprocessor.transform(final)\n",
    "\n",
    "# Flatten the target variable y\n",
    "y_data = y.values.ravel()\n",
    "\n",
    "# Calculate scale_pos_weight for XGBClassifier\n",
    "scale_pos_weight = (len(y_data) - y_data.sum()) / y_data.sum()\n",
    "\n",
    "# Initialize BaggingClassifier & XGBClassifier with best hyperparameters\n",
    "best_model = BaggingClassifier(\n",
    "            estimator=XGBClassifier(n_estimators=300, scale_pos_weight=scale_pos_weight, objective=\"binary:logistic\", \n",
    "                                    random_state=42, **best_params),n_estimators=70,\n",
    "            random_state=42,\n",
    "            bootstrap=True, **bp\n",
    "        )\n",
    "# Fit the best_model on the preprocessed training data\n",
    "best_model.fit(X_pre, y_data)\n",
    "y_pred_prob = best_model.predict_proba(final_pre)[:,1]\n",
    "# Make predictions on the preprocessed test data\n",
    "final_predictions =  best_model.predict(final_pre)\n",
    "final_predictions = np.where(final_predictions == 0, 1, 2)\n",
    "\n",
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'ID': ID_array,\n",
    "    'label': final_predictions\n",
    "})\n",
    "# Save results to CSV file\n",
    "predictions_df.to_csv(\"submission.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75695d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4730185,
     "sourceId": 8026236,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
